{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43ITKqYF5qFM"
   },
   "source": [
    "<div >\n",
    "<img src = \"figures_notebook/banner.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Intro\n",
    "=====\n",
    "\n",
    "### Deep Learning: Intro\n",
    "\n",
    "-   Neural networks are simple models.\n",
    "\n",
    "-   Their strength lays in their simplicity\n",
    "\n",
    "-   The model has linear combinations of inputs that are passed through\n",
    "    nonlinear activation functions called nodes (or, in reference to the\n",
    "    human brain, neurons).\n",
    "\n",
    "-   Let's start with a familiar and simple model, the linear model\n",
    "\n",
    "$$\\begin{aligned}\n",
    "y &= f(X) + u \\\\ \\nonumber\n",
    "y &=  \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3  + u\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figures_notebook/red1.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Single Layer Neural Networks\n",
    "============================\n",
    "\n",
    "### Single Layer Neural Networks\n",
    "\n",
    "-   Linear Models may miss the nonlinearities that best approximate\n",
    "    $f^*(x)$\n",
    "\n",
    "-   We can overcome these limitations of linear models and handle a more\n",
    "    general class of functions by incorporating hidden layers.\n",
    "\n",
    "-   Neural Networks are also called deep feedforward networks,\n",
    "    feedforward neural networks, or multilayer perceptrons (MLPs), and\n",
    "    are the quintessential deep learning models\n",
    "\n",
    "-   A neural network takes an input vector of $p$ variables\n",
    "    $$\\begin{aligned}\n",
    "        X = (X_1, X_2, . . . , X_p)     \n",
    "        \\end{aligned}$$\n",
    "\n",
    "-   and builds a nonlinear function $f(X)$ to predict the response $y$ .\n",
    "    $$\\begin{aligned}\n",
    "        y = f(X) +u \n",
    "        \\end{aligned}$$\n",
    "\n",
    "-   What distinguishes neural networks from previous methods is the\n",
    "    particular structure of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figures_notebook/red2.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-   The NN model has the form $$\\begin{aligned}\n",
    "            f(X)    &= f \\left(\\beta_0 + \\sum_{k=1}^K \\beta_k h_k(X)\\right) \\\\\n",
    "                &= f \\left(\\beta_0 + \\sum_{k=1}^K \\beta_k g\\left(w_{k0} + \\sum_{j=1}^p w_{kj} X_j \\right)\\right)\n",
    "        \\end{aligned}$$\n",
    "\n",
    "-   where \n",
    "    - $f()$ is the output function\n",
    "    - $g(.)$ is a activation function specified in advance, the nonlinearity of $g(.)$ is **essential**\n",
    "\n",
    "\n",
    "\n",
    "### Worked Example I: Single Layer Neural Networks\n",
    "\n",
    "-   $p=2$, $X=(X_1,X_2)$\n",
    "\n",
    "-   $K=2$, $h_1(X)$ and $h_2(X)$\n",
    "\n",
    "-   $g(z)=z^2$\n",
    "\n",
    "-   $f(x)=x$ \n",
    "\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "  f(X) &= \\beta_0 + \\sum_{k=1}^2 \\beta_k g\\left(w_{k0} + \\sum_{j=1}^2 w_{kj} X_j \\right)\n",
    "  \\end{aligned}\n",
    "  \n",
    "\n",
    "-   Suppose we get\n",
    "\n",
    "       \n",
    "       $\\hat{\\beta}_0 =0$  \n",
    "       $\\hat{\\beta}_1 =\\frac{1}{4}$   \n",
    "       $\\hat{\\beta}_2 =-\\frac{1}{4}$\n",
    "        \n",
    "       $\\hat{w}_{10} =0$        \n",
    "       \n",
    "       $\\hat{w}_{11} =1$               \n",
    "       \n",
    "       $\\hat{w}_{12} =1$\n",
    "       $\\hat{w}_{20} =0$         \n",
    "       $\\hat{w}_{21} =1$              \n",
    "       $\\hat{w}_{22} =-1$\n",
    "      \n",
    "\n",
    "- Then\n",
    "\n",
    "\n",
    "    \\begin{align}\n",
    "      h_1(X) &= \\left(0 + X_1 + X_2\\right)^2 \\\\\n",
    "      h_2(X) &= \\left(0 + X_1 - X_2\\right)^2 \n",
    "  \\end{align}\n",
    "\n",
    "-  and plugging in \n",
    "\n",
    "    \\begin{align}\n",
    "      f(X) &=  0 + \\frac{1}{4} \\left(0 + X_1 + X_2\\right)^2   - \\frac{1}{4} \\left(0 + X_1 - X_2\\right)^2 \\\\\n",
    "            &= \\frac{1}{4} \\left(\\left(X_1 + X_2\\right)^2   -  \\left( X_1 - X_2\\right)^2 \\right) \\\\\n",
    "            &= X_1X_2\n",
    "    \\end{align}\n",
    "\n",
    "\n",
    "\n",
    "### NN Minimalist Theory\n",
    "\n",
    "-   Why not a linear activation functions?\n",
    "\n",
    "-   Let's go back to our example\n",
    "\n",
    "    -   $p=2$, $X=(X_1,X_2)$\n",
    "\n",
    "    -   $K=2$, $h_1(X)$ and $h_2(X)$\n",
    "\n",
    "    -   Now $g(z)=z$\n",
    "\n",
    "-   Then \n",
    "                \n",
    "\n",
    "\\begin{align}\n",
    "f(X)  &= \\beta_0 + \\sum_{k=1}^2 \\beta_k h_k(X) \\\\\n",
    "   &= \\beta_0 + \\sum_{k=1}^2 \\beta_k \\left(w_{k0} + \\sum_{j=1}^2 w_{kj} X_j \\right)\n",
    "\\end{align}\n",
    "\n",
    "- Replacing\n",
    "\n",
    "\\begin{align}\n",
    "  f(X) &= \\beta_0 +  \\beta_1 \\left(w_{10} + w_{11} X_1 + w_{12} X_2 \\right) +  \\beta_2 \\left(w_{20} + w_{21} X_1 + w_{22} X_2 \\right)\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "  f(X) &= \\theta_0 +  \\theta_1  X_1 + \\theta_2 X_2\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "### Worked Example II : The \\\"Exclusive OR (XOR)\\\" Function\n",
    "\n",
    "-   The exclusive disjunction of a pair of propositions, (p, q), is\n",
    "    supposed to mean that p is true or q is true, but not both\n",
    "\n",
    "-   It's truth table is:\n",
    "\n",
    "q  | p | q v p \n",
    "---|---|------|\n",
    "0 | 0 | 0 |\n",
    "0 | 1 | 1 |\n",
    "1 | 0 | 1 |\n",
    "1 | 1 | 0 |        \n",
    "\n",
    "-   When exactly one of these binary values is equal to 1, the XOR\n",
    "    function returns 1. Otherwise, it returns 0\n",
    "\n",
    "\n",
    "\n",
    "-   Let's use a linear model\n",
    "\n",
    "    $$\\begin{aligned}\n",
    "    y = \\beta_0 + \\beta_1 q + \\beta_2 p +u\\end{aligned}$$\n",
    "\n",
    "    $$\\begin{aligned}\n",
    "     y=\\left(\\begin{array}{c}\n",
    "    0\\\\\n",
    "    1\\\\\n",
    "    1\\\\\n",
    "    0\n",
    "    \\end{array}\\right)X=\\left(\\begin{array}{cc}\n",
    "    0 & 0\\\\\n",
    "    0 &1\\\\\n",
    "    1 & 0\\\\\n",
    "    1 & 1\n",
    "    \\end{array}\\right)1=\\left(\\begin{array}{c}\n",
    "    1\\\\\n",
    "    1\\\\\n",
    "    1\\\\\n",
    "    1\n",
    "    \\end{array}\\right)\n",
    "     \\end{aligned}$$\n",
    "\n",
    "-   Solution $\\beta_0=\\frac{1}{2}$, $\\beta_1=0$, $\\beta_2 =0$\n",
    "\n",
    "-   Prediction $\\hat{y}=\\left(\\begin{array}{c}\n",
    "    \\frac{1}{2}\\\\\n",
    "    \\frac{1}{2}\\\\\n",
    "    \\frac{1}{2}\\\\\n",
    "    \\frac{1}{2}\n",
    "    \\end{array}\\right)$\n",
    "\n",
    "\n",
    "\n",
    "-   Let's use Single Layer NN containing two hidden units\n",
    "\n",
    "-   Activation Funcition: ReLU: $g(z)=max\\{0,z\\}$\n",
    "\n",
    "-   NN $$\\begin{aligned}\n",
    "        f(X)  &= \\beta_0 + \\sum_{k=1}^2 \\beta_k g\\left(w_{k0} + \\sum_{j=1}^2 w_{kj} X_j \\right)\\end{aligned}$$\n",
    "\n",
    "\n",
    "-   Suppose this is the solution to the XOR problem\n",
    "\n",
    "$$f(x)=max\\{0,XW+W_0\\}\\,\\beta+\\beta_0$$\n",
    "\n",
    "$$W=\\left(\\begin{array}{cc}\n",
    "1 & 1\\\\\n",
    "1 & 1\n",
    "\\end{array}\\right)$$\n",
    "\n",
    "$$W_0=\\left(\\begin{array}{cc}\n",
    "0 & -1\\\\\n",
    "0 & -1\\\\\n",
    "0 & -1\\\\\n",
    "0 & -1\n",
    "\\end{array}\\right)$$\n",
    "\n",
    "$$\\beta=\\left(\\begin{array}{cc}\n",
    "1 & -2\\end{array}\\right)$$\n",
    "\n",
    "$$\\beta_0 = 0$$\n",
    "\n",
    "\n",
    "-   Lets work out the example step by step\n",
    "\\begin{align}\n",
    "f(x)=max\\{0,XW+W_0\\}\\,\\beta+\\beta_0\n",
    "\\end{align}\n",
    "\n",
    "$$\n",
    "XW=\\left(\\begin{array}{cc}\n",
    "0 & 0\\\\\n",
    "0 &1\\\\\n",
    "1 & 0\\\\\n",
    "1 & 1\n",
    "\\end{array}\\right)\\left(\\begin{array}{cc}\n",
    "1 & 1\\\\\n",
    "1 & 1\n",
    "\\end{array}\\right)=\\left(\\begin{array}{cc}\n",
    "0 & 0\\\\\n",
    "1 & 1\\\\\n",
    "1 & 1\\\\\n",
    "2 & 2\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "XW+W_0=\\left(\\begin{array}{cc}\n",
    "0 & -1\\\\\n",
    "1 & 0\\\\\n",
    "1 & 0\\\\\n",
    "2 & 1\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "max\\{0,XW+W_0\\}=\\left(\\begin{array}{cc}\n",
    "0 & 0\\\\\n",
    "1 & 0\\\\\n",
    "1 & 0\\\\\n",
    "2 & 1\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y}=max\\{0,XW+W_0\\}\\,\\beta + \\beta_0=\\left(\\begin{array}{cc}\n",
    "0 & 0\\\\\n",
    "1 & 0\\\\\n",
    "1 & 0\\\\\n",
    "2 & 1\n",
    "\\end{array}\\right)\\left(\\begin{array}{cc}\n",
    "1 \\\\ -2\\end{array}\\right)+ 0 =\\left(\\begin{array}{c}\n",
    "0\\\\\n",
    "1\\\\\n",
    "1\\\\\n",
    "0\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-   In this example, we simply specified the solution, then showed that\n",
    "    it obtained zero error.\n",
    "\n",
    "-   In a real situation, obviously we can't guess the solution\n",
    "\n",
    "-   What we do is to estimate the parameters via optimization methods\n",
    "\n",
    "-   All gain comes from using nonlinear activation function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "q  | p | q v p \n",
    "---|---|------|\n",
    "0 | 0 | 0 |\n",
    "0 | 1 | 1 |\n",
    "1 | 0 | 1 |\n",
    "1 | 1 | 0 |\n",
    "\n",
    "\n",
    "## Llamando las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cK7Bc6JE5k6V",
    "outputId": "46b1e070-b46b-4a54-f490-bbfab0f3559a",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# install.packages(\"pacman\") #run this line if you use Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: pacman\n",
      "\n"
     ]
    }
   ],
   "source": [
    "require('pacman')\n",
    "p_load(\"tidyverse\",\"keras\",'caret')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 4 × 2 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>0</td><td>1</td></tr>\n",
       "\t<tr><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 2 of type dbl\n",
       "\\begin{tabular}{ll}\n",
       "\t 0 & 0\\\\\n",
       "\t 0 & 1\\\\\n",
       "\t 1 & 0\\\\\n",
       "\t 1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 2 of type dbl\n",
       "\n",
       "| 0 | 0 |\n",
       "| 0 | 1 |\n",
       "| 1 | 0 |\n",
       "| 1 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]\n",
       "[1,] 0    0   \n",
       "[2,] 0    1   \n",
       "[3,] 1    0   \n",
       "[4,] 1    1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X<-matrix(c(0,0,0,1,1,0,1,1),nrow=4,byrow=TRUE)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 4 × 1 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 1 of type dbl\n",
       "\\begin{tabular}{l}\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 1 of type dbl\n",
       "\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]\n",
       "[1,] 0   \n",
       "[2,] 1   \n",
       "[3,] 1   \n",
       "[4,] 0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y<-matrix(c(0,1,1,0),nrow=4,byrow=TRUE)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamos la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model <- keras_model_sequential() \n",
    "\n",
    "model %>% \n",
    "  layer_dense(units = 16, activation = 'relu', input_shape = c(2)) %>% #activación\n",
    "  layer_dense(units = 1, activation = 'sigmoid') #output\n",
    "\n",
    "model %>% compile(\n",
    "  optimizer = 'adam',\n",
    "  loss = 'binary_crossentropy',\n",
    "  metrics = c('binary_accuracy')\n",
    ")\n",
    "\n",
    "history <- model %>% fit(\n",
    "  X, y, \n",
    "  epochs = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "dense_1 (Dense)                     (None, 16)                      48          \n",
      "________________________________________________________________________________\n",
      "dense (Dense)                       (None, 1)                       17          \n",
      "================================================================================\n",
      "Total params: 65\n",
      "Trainable params: 65\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 4 × 1 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 1 of type dbl\n",
       "\\begin{tabular}{l}\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 1 of type dbl\n",
       "\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]\n",
       "[1,] 0   \n",
       "[2,] 1   \n",
       "[3,] 1   \n",
       "[4,] 0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_hat <- model  %>% predict(X) \n",
    "y_hat <- ifelse(y_hat>0.5,1,0)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction 0 1\n",
       "         0 2 0\n",
       "         1 0 2\n",
       "                                     \n",
       "               Accuracy : 1          \n",
       "                 95% CI : (0.3976, 1)\n",
       "    No Information Rate : 0.5        \n",
       "    P-Value [Acc > NIR] : 0.0625     \n",
       "                                     \n",
       "                  Kappa : 1          \n",
       "                                     \n",
       " Mcnemar's Test P-Value : NA         \n",
       "                                     \n",
       "            Sensitivity : 1.0        \n",
       "            Specificity : 1.0        \n",
       "         Pos Pred Value : 1.0        \n",
       "         Neg Pred Value : 1.0        \n",
       "             Prevalence : 0.5        \n",
       "         Detection Rate : 0.5        \n",
       "   Detection Prevalence : 0.5        \n",
       "      Balanced Accuracy : 1.0        \n",
       "                                     \n",
       "       'Positive' Class : 0          \n",
       "                                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = factor(as.numeric(y_hat), levels = 0:1), \n",
    "  reference = factor(y, levels = 0:1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyN44b+botaWmeiTQ/7e9hxl",
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
